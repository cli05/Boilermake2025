{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "318d2897-06c9-4428-bae1-e1230236a120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c772ce9a-fc2a-4ac4-ab0f-994d55d59ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    # Valence\n",
    "    \"happy\": [0.7, 1.0],\n",
    "    \"neutral_mood\": [0.3, 0.7],\n",
    "    \"sad\": [0.0, 0.3],\n",
    "\n",
    "    # Popularity\n",
    "    \"high_popularity\": [0.7, 1.0],\n",
    "    \"mid_popularity\": [0.3, 0.7],\n",
    "    \"low_popularity\": [0.0, 0.3],\n",
    "\n",
    "    # Duration (normalized to [0.0, 1.0])\n",
    "    \"long_duration\": [0.7, 1.0],\n",
    "    \"medium_duration\": [0.3, 0.7],\n",
    "    \"short_duration\": [0.0, 0.3],\n",
    "\n",
    "    # Danceability\n",
    "    \"high_danceability\": [0.7, 1.0],\n",
    "    \"mid_danceability\": [0.3, 0.7],\n",
    "    \"low_danceability\": [0.0, 0.3],\n",
    "\n",
    "    # Energy\n",
    "    \"high_energy\": [0.7, 1.0],\n",
    "    \"mid_energy\": [0.3, 0.7],\n",
    "    \"low_energy\": [0.0, 0.3],\n",
    "\n",
    "    # Loudness (normalized to [0.0, 1.0])\n",
    "    \"high_loudness\": [0.7, 1.0],\n",
    "    \"mid_loudness\": [0.3, 0.7],\n",
    "    \"low_loudness\": [0.0, 0.3],\n",
    "\n",
    "    # Speechiness\n",
    "    \"high_speechiness\": [0.7, 1.0],\n",
    "    \"mid_speechiness\": [0.3, 0.7],\n",
    "    \"low_speechiness\": [0.0, 0.3],\n",
    "\n",
    "    # Acousticness\n",
    "    \"high_acousticness\": [0.7, 1.0],\n",
    "    \"mid_acousticness\": [0.3, 0.7],\n",
    "    \"low_acousticness\": [0.0, 0.3],\n",
    "\n",
    "    # Instrumentalness\n",
    "    \"high_instrumentalness\": [0.7, 1.0],\n",
    "    \"mid_instrumentalness\": [0.3, 0.7],\n",
    "    \"low_instrumentalness\": [0.0, 0.3],\n",
    "\n",
    "    # Liveness\n",
    "    \"high_liveness\": [0.7, 1.0],\n",
    "    \"mid_liveness\": [0.3, 0.7],\n",
    "    \"low_liveness\": [0.0, 0.3],\n",
    "\n",
    "    # Tempo (normalized to [0.0, 1.0])\n",
    "    \"high_tempo\": [0.7, 1.0],\n",
    "    \"mid_tempo\": [0.3, 0.7],\n",
    "    \"low_tempo\": [0.0, 0.3],\n",
    "\n",
    "    #Explicity\n",
    "    \"explicit\": True,\n",
    "    \"not_explicit\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c731b86-5974-4a78-aa46-bbcad77f8b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                track_id                 artists  \\\n",
      "0           0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
      "1           1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
      "2           2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
      "3           3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
      "4           4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
      "\n",
      "                                          album_name  \\\n",
      "0                                             Comedy   \n",
      "1                                   Ghost (Acoustic)   \n",
      "2                                     To Begin Again   \n",
      "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
      "4                                            Hold On   \n",
      "\n",
      "                   track_name  popularity  duration_ms  explicit  \\\n",
      "0                      Comedy          73       230666     False   \n",
      "1            Ghost - Acoustic          55       149610     False   \n",
      "2              To Begin Again          57       210826     False   \n",
      "3  Can't Help Falling In Love          71       201933     False   \n",
      "4                     Hold On          82       198853     False   \n",
      "\n",
      "   danceability  energy  ...  popularity_normalized  duration_ms_normalized  \\\n",
      "0         0.676  0.4610  ...                   0.73                0.042473   \n",
      "1         0.420  0.1660  ...                   0.55                0.026971   \n",
      "2         0.438  0.3590  ...                   0.57                0.038679   \n",
      "3         0.266  0.0596  ...                   0.71                0.036978   \n",
      "4         0.618  0.4430  ...                   0.82                0.036389   \n",
      "\n",
      "   danceability_normalized  energy_normalized  loudness_normalized  \\\n",
      "0                 0.686294             0.4610             0.791392   \n",
      "1                 0.426396             0.1660             0.597377   \n",
      "2                 0.444670             0.3590             0.736123   \n",
      "3                 0.270051             0.0596             0.573701   \n",
      "4                 0.627411             0.4430             0.737103   \n",
      "\n",
      "   speechiness_normalized  acousticness_normalized  \\\n",
      "0                0.148187                 0.032329   \n",
      "1                0.079067                 0.927711   \n",
      "2                0.057720                 0.210843   \n",
      "3                0.037617                 0.908635   \n",
      "4                0.054508                 0.470884   \n",
      "\n",
      "   instrumentalness_normalized  liveness_normalized  tempo_normalized  \n",
      "0                     0.000001               0.3580          0.361245  \n",
      "1                     0.000006               0.1010          0.318397  \n",
      "2                     0.000000               0.1170          0.313643  \n",
      "3                     0.000071               0.1320          0.746758  \n",
      "4                     0.000000               0.0829          0.492863  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define min and max values for each feature (adjust based on your dataset)\n",
    "feature_ranges = {\n",
    "    \"valence\": (0.0, 1.0),\n",
    "    \"popularity\": (0, 100),\n",
    "    \"duration_ms\": (8586, 5237295),  # Adjust based on your dataset\n",
    "    \"danceability\": (0.0, 0.985),\n",
    "    \"energy\": (0.0, 1.0),\n",
    "    \"loudness\": (-49.531, 4.532),  # Loudness ranges from -60 dB to 0 dB\n",
    "    \"speechiness\": (0.0, 0.965),\n",
    "    \"acousticness\": (0.0, 0.996),\n",
    "    \"instrumentalness\": (0.0, 1.0),\n",
    "    \"liveness\": (0.0, 1.0),\n",
    "    \"tempo\": (0, 243.372),  # Tempo ranges from 0 BPM to 250 BPM\n",
    "}\n",
    "\n",
    "# Normalize features to [0.0, 1.0]\n",
    "for feature, (min_val, max_val) in feature_ranges.items():\n",
    "    df[f\"{feature}_normalized\"] = (df[feature] - min_val) / (max_val - min_val)\n",
    "\n",
    "# Display the updated dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9396466-dbbf-4b86-9a99-0d451159c60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['happy', 'neutral_mood', 'sad', 'high_popularity', 'mid_popularity', 'low_popularity', 'long_duration', 'medium_duration', 'short_duration', 'high_danceability', 'mid_danceability', 'low_danceability', 'high_energy', 'mid_energy', 'low_energy', 'high_loudness', 'mid_loudness', 'low_loudness', 'high_speechiness', 'mid_speechiness', 'low_speechiness', 'high_acousticness', 'mid_acousticness', 'low_acousticness', 'high_instrumentalness', 'mid_instrumentalness', 'low_instrumentalness', 'high_liveness', 'mid_liveness', 'low_liveness', 'high_tempo', 'mid_tempo', 'low_tempo', 'explicit', 'not_explicit', 'acoustic', 'afrobeat', 'alt-rock', 'alternative', 'ambient', 'anime', 'black-metal', 'bluegrass', 'blues', 'brazil', 'breakbeat', 'british', 'cantopop', 'chicago-house', 'children', 'chill', 'classical', 'club', 'comedy', 'country', 'dance', 'dancehall', 'death-metal', 'deep-house', 'detroit-techno', 'disco', 'disney', 'drum-and-bass', 'dub', 'dubstep', 'edm', 'electro', 'electronic', 'emo', 'folk', 'forro', 'french', 'funk', 'garage', 'german', 'gospel', 'goth', 'grindcore', 'groove', 'grunge', 'guitar', 'hard-rock', 'hardcore', 'hardstyle', 'heavy-metal', 'hip-hop', 'honky-tonk', 'house', 'idm', 'indian', 'indie-pop', 'indie', 'industrial', 'iranian', 'j-dance', 'j-idol', 'j-pop', 'j-rock', 'jazz', 'k-pop', 'kids', 'latin', 'latino', 'malay', 'mandopop', 'metal', 'metalcore', 'minimal-techno', 'mpb', 'new-age', 'opera', 'pagode', 'party', 'piano', 'pop-film', 'pop', 'power-pop', 'progressive-house', 'psych-rock', 'punk-rock', 'punk', 'r-n-b', 'reggae', 'reggaeton', 'rock-n-roll', 'rock', 'rockabilly', 'romance', 'salsa', 'samba', 'sertanejo', 'show-tunes', 'singer-songwriter', 'ska', 'sleep', 'songwriter', 'soul', 'spanish', 'study', 'swedish', 'synth-pop', 'tango', 'techno', 'trance', 'trip-hop', 'turkish', 'world-music'])\n"
     ]
    }
   ],
   "source": [
    "for index, rows in df.iterrows():\n",
    "    if rows[\"track_genre\"] not in labels:\n",
    "        labels[rows[\"track_genre\"]] = None\n",
    "\n",
    "print(labels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "828aa338-e4bd-4381-872b-9dab8537dfcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da317bb085754ba1914aeac969277732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe6f2dc4e4d40eb8c67ac642ead91f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/870M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909c4d74837649b4bb2dc2dfe595680c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.26k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffef9011540a4c5da28041f1a3d1039f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0fbc83bed0348a189ebc049e0e43e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/8.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93b1fcf486247fe8cb4dc8e028fdcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c28ff4a1ef0429abcdd102d71677347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/970 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict_keys' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m classes_verbalized \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m      4\u001b[0m zeroshot_classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMoritzLaurer/deberta-v3-large-zeroshot-v2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# change the model identifier here\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m output \u001b[38;5;241m=\u001b[39m zeroshot_classifier(text, classes_verbalized, hypothesis_template\u001b[38;5;241m=\u001b[39mhypothesis_template, multi_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/zero_shot_classification.py:206\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(sequences, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/base.py:1360\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1362\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1363\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1364\u001b[0m             )\n\u001b[1;32m   1365\u001b[0m         )\n\u001b[1;32m   1366\u001b[0m     )\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:32\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_iter))\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:186\u001b[0m, in \u001b[0;36mPipelineChunkIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubiterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# Try to return next item\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubiterator)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# When a preprocess iterator ends, we can start lookig at the next item\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# ChunkIterator will keep feeding until ALL elements of iterator\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# Another way to look at it, is we're basically flattening lists of lists\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# into a single list, but with generators\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubiterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/zero_shot_classification.py:209\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.preprocess\u001b[0;34m(self, inputs, candidate_labels, hypothesis_template)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, candidate_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, hypothesis_template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis example is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 209\u001b[0m     sequence_pairs, sequences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args_parser(inputs, candidate_labels, hypothesis_template)\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (candidate_label, sequence_pair) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(candidate_labels, sequence_pairs)):\n\u001b[1;32m    212\u001b[0m         model_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_and_tokenize([sequence_pair])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/zero_shot_classification.py:28\u001b[0m, in \u001b[0;36mZeroShotClassificationArgumentHandler.__call__\u001b[0;34m(self, sequences, labels, hypothesis_template)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sequences) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must include at least one label and at least one sequence.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hypothesis_template\u001b[38;5;241m.\u001b[39mformat(labels[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m==\u001b[39m hypothesis_template:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     30\u001b[0m         (\n\u001b[1;32m     31\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe provided hypothesis_template \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m was not able to be formatted with the target labels. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     32\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure the passed template includes formatting syntax such as \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m}} where the label should go.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(hypothesis_template)\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sequences, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict_keys' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "text = \"I want a happy song\"\n",
    "hypothesis_template = \"This text is about {}\"\n",
    "classes_verbalized = labels.keys()\n",
    "zeroshot_classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\")  # change the model identifier here\n",
    "output = zeroshot_classifier(text, classes_verbalized, hypothesis_template=hypothesis_template, multi_label=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e18ca49-3174-43d4-96c2-36940c0caab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
